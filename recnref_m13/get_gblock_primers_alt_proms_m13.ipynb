{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqUtils import GC\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import primer3\n",
    "import statistics\n",
    "import time\n",
    "import gffpandas.gffpandas as gffpd\n",
    "from functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "from dna_features_viewer import BiopythonTranslator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook makes primers with an input sequence to be assemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################################################################################### #\n",
    "#                                                                                                                             #\n",
    "# THIS CELL IS USEFULL ONLY AND ONLY IF U USE gff3 file provided with generate_recoded_and_refactored_genome                  #\n",
    "#                                                                                                                             #\n",
    "# ########################################################################################################################### #\n",
    "\n",
    "def merge_intervals(intervals):\n",
    "    #get list of tuple as input\n",
    "    sorted_by_lower_bound = sorted(intervals, key=lambda tup: tup[0])\n",
    "    merged = []\n",
    "\n",
    "    for higher in sorted_by_lower_bound:\n",
    "        if not merged:\n",
    "            merged.append(higher)\n",
    "        else:\n",
    "            lower = merged[-1]\n",
    "            # test for intersection between lower and higher:\n",
    "            # we know via sorting that lower[0] <= higher[0]\n",
    "            if higher[0] <= lower[1]:\n",
    "                upper_bound = max(lower[1], higher[1])\n",
    "                merged[-1] = (lower[0], upper_bound)  # replace by merged interval\n",
    "            else:\n",
    "                merged.append(higher)\n",
    "    return merged\n",
    "\n",
    "def get_restricted_region_from_ourgff3(path_to_wt_fasta,path_to_annotation_df,path_to_recnref_fasta,start_sequence,end_sequence,term_filename):\n",
    "    #the wtz and recnref version must have same pcr primers. Exclude the different region of the two versions to create a list of forbidden places for primers.\n",
    "    wt_fasta = SeqIO.read(path_to_wt_fasta, \"fasta\").seq\n",
    "    annotation_df = (gffpd.read_gff3(path_to_annotation_df)).df\n",
    "    # set annotation to 0 based\n",
    "    annotation_df['start'] -= 1\n",
    "    recnref_genome = SeqIO.read(path_to_recnref_fasta, \"fasta\").seq\n",
    "    \n",
    "    #Find the beginning of the fasta recnref file:\n",
    "    start = recnref_genome.find(start_sequence)\n",
    "    end = recnref_genome.find(end_sequence)+len(end_sequence)\n",
    "    \n",
    "    print('start',start,'end',end)\n",
    "    \n",
    "    #wt_start: usefull when the terminator files are based on the wt_fasta file of L1.\n",
    "    #define the beginning of the fasta file provided\n",
    "    wt_start = wt_fasta.find(start_sequence)\n",
    "    #last primer: find the end\n",
    "    wt_end = wt_fasta.find(end_sequence)+len(end_sequence)\n",
    "\n",
    "    annotation_df = annotation_df.loc[(annotation_df[\"start\"] >= start) & (end >= annotation_df[\"end\"])]\n",
    "\n",
    "    annotation_df.drop([\"seq_id\",\"source\",\"type\",'score',\"phase\",], axis=1, inplace=True)\n",
    "    annotation_df['start'] -= start\n",
    "    annotation_df[\"end\"] -= start\n",
    "    annotation_df = annotation_df.rename(columns={\"attributes\": 'name'})\n",
    "    annotation_df = annotation_df[['name', 'start', 'end', 'strand']]\n",
    "    \n",
    "    #REMOVE THE FIRST COLUMN:\n",
    "    annotation_df = annotation_df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "    #create a list of excluded coordinates: restricted region (including reedited parts) with only the recnref file\n",
    "    restricted_region = []\n",
    "    for idx, attributes in enumerate(annotation_df[\"name\"]):\n",
    "        if \"rec\" not in attributes:\n",
    "            restricted_region.append((annotation_df['start'][idx],annotation_df['end'][idx]))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    #print('je suis restricted_region',restricted_region)\n",
    "    # Merge initial restricted regions:\n",
    "    # There is always maximum 2 overlapping regions in restricted_region:\n",
    "      \n",
    "                \n",
    "    #####We have to add the terminator region as restricted regions:\n",
    "    # those are 0-based, no coords modification needed\n",
    "    terminator_df = pd.read_csv(term_filename, sep=\"\\t\")\n",
    "    for i in range(len(terminator_df)):\n",
    "        if terminator_df[\"term start\"][i] > wt_start and terminator_df[\"term stop\"][i] < wt_end:\n",
    "            term_start = int(terminator_df[\"term start\"][i])\n",
    "            term_end = int(terminator_df[\"term stop\"][i])\n",
    "    # I had the proof these coordinates work:\n",
    "            terminator_seq = str(wt_fasta[term_start:term_end])\n",
    "            restricted_region.append((ref_40kbfasta.find(terminator_seq),ref_40kbfasta.find(terminator_seq)+len(terminator_seq)))\n",
    "\n",
    "    # Position to add other annotations, be careful, we are using 0 based annotation!\n",
    "    # So we must correct positions when importing gff annotations\n",
    "            \n",
    "    restricted_region = merge_intervals(restricted_region)\n",
    "    restricted_region = [str(i[0])+':'+str(i[1]) for i in restricted_region]\n",
    "\n",
    "    return restricted_region\n",
    "\n",
    "\n",
    "# def get_annotation_df_from_gff3(path_to_wt_fasta,path_to_annotation_df,path_to_recnref_fasta):\n",
    "#     wt_fasta = SeqIO.read(path_to_wt_fasta, \"fasta\").seq\n",
    "#     annotation_df = (gffpd.read_gff3(path_to_annotation_df)).df\n",
    "#     # set annotation to 0 based\n",
    "#     annotation_df['start'] -= 1\n",
    "#     recnref_genome = SeqIO.read(path_to_recnref_fasta, \"fasta\").seq\n",
    "\n",
    "\n",
    "#     #Find the beginning of the fasta recnref file:\n",
    "#     start = recnref_genome.find('TAGTAGAGGTAAAATATG')\n",
    "#     end = recnref_genome.find('TAGAACTAAACACTAG')+len('TAGAACTAAACACTAG')\n",
    "\n",
    "#     annotation_df = annotation_df.loc[(annotation_df[\"start\"] >= start) & (end >= annotation_df[\"end\"])]\n",
    "#     annotation_df.drop([\"seq_id\",\"source\",\"type\",'score',\"phase\",], axis=1, inplace=True)\n",
    "#     annotation_df['start'] -= start\n",
    "#     annotation_df[\"end\"] -= start\n",
    "#     annotation_df = annotation_df.rename(columns={\"attributes\": 'name'})\n",
    "#     annotation_df = annotation_df[['name', 'start', 'end', 'strand']]\n",
    "#     print(annotation_df)\n",
    "#     #REINDEX THE FIRST COLUMN:\n",
    "#     annotation_df = annotation_df.iloc[0:].reset_index(drop=True)\n",
    "#     return annotation_df\n",
    "\n",
    "def get_number_of_primers(len_min,len_max,len_fragment):\n",
    "    i = len_min\n",
    "    number_of_primers = 0\n",
    "    while i <= len_max:\n",
    "        number_of_primers = number_of_primers + (len_fragment-(i-1))\n",
    "        i+=1\n",
    "    return number_of_primers\n",
    "\n",
    "def primer_dict_to_df(dict):\n",
    "    pair_list = []\n",
    "    number_of_pairs = dict['PRIMER_PAIR_NUM_RETURNED']\n",
    "    try:\n",
    "        for i in range(number_of_pairs):\n",
    "            pair_list = pair_list + [{\n",
    "                'PRIMER_LEFT_SEQUENCE' : dict['PRIMER_LEFT_'+str(i)+'_SEQUENCE'],\n",
    "                'PRIMER_RIGHT_SEQUENCE' : dict['PRIMER_RIGHT_'+str(i)+'_SEQUENCE'],\n",
    "                'PRIMER_LEFT_POSITION' : dict['PRIMER_LEFT_'+str(i)][0],\n",
    "                'PRIMER_RIGHT_POSITION' : dict['PRIMER_RIGHT_'+str(i)][0],\n",
    "                'PRIMER_LEFT_TM': dict['PRIMER_LEFT_'+str(i)+'_TM'],\n",
    "                'PRIMER_RIGHT_TM': dict['PRIMER_RIGHT_'+str(i)+'_TM'],\n",
    "                'PRIMER_PENALTY' : statistics.mean([dict['PRIMER_LEFT_'+str(i)+'_PENALTY'],dict['PRIMER_RIGHT_'+str(i)+'_PENALTY']])\n",
    "            }]\n",
    "    except:\n",
    "        print(dict)\n",
    "        print(\"censored\")\n",
    "    return pd.DataFrame(pair_list)\n",
    "\n",
    "#Define parameters to give to this functions:\n",
    "def make_sequencing_primers_rec(seq, fragment_number,coordinates_sequence_template, prev, min_overlap_len, max_overlap_len, \n",
    "                                window_len,restricted_region_ordered, index, is_starting = False, verbose = False, recoil_number = [], liste_primers_d = []):\n",
    "    \"\"\"\n",
    "    This is a recursive function giving the best primers found with Primer3.\n",
    "    \"\"\"\n",
    "    if verbose:print(fragment_number)\n",
    "    if fragment_number == 0:\n",
    "        \n",
    "        #safety purposes\n",
    "        if is_starting:\n",
    "            if len(recoil_number) > 0:\n",
    "                if verbose:print(\"le fragment_number n'est pas bien initialise, mais nous avons corrige le tir\")\n",
    "                recoil_number = []\n",
    "            if len(liste_primers_d) > 0:\n",
    "                if verbose:print(\"la liste_primers_d n'est pas bien initialisee, mais nous avons corrige le tir\")\n",
    "                liste_primers_d = []\n",
    "            is_starting = False\n",
    "\n",
    "        #Find right coordinates\n",
    "        coordinates_sequence_template = find_right_coordinates(index,restricted_region_ordered,max_overlap_len,window_len,prev[fragment_number],0,verbose)\n",
    "\n",
    "        if verbose:print('je suis coordinates_sequence_template : '+str(coordinates_sequence_template))\n",
    "        if verbose:print('current_coordinates_sequence_template : '+str(coordinates_sequence_template))\n",
    "        if verbose:print('type de current_coordinates_sequence_template : '+str(type(coordinates_sequence_template[0])))\n",
    "\n",
    "        #Primer3 design primer with these parameters:\n",
    "        primers = (primer3.bindings.designPrimers(\n",
    "            {\n",
    "                'SEQUENCE_ID': 'debut',\n",
    "                'SEQUENCE_TEMPLATE': str(seq[:coordinates_sequence_template[1]]),\n",
    "                'SEQUENCE_EXCLUDED_REGION': [0,coordinates_sequence_template[1]-max_overlap_len],\n",
    "                'SEQUENCE_PRIMER': first_left_primer_sequence\n",
    "            },\n",
    "            {\n",
    "                'PRIMER_TASK': 'generic',\n",
    "                'PRIMER_PICK_LEFT_PRIMER': 0,\n",
    "                'PRIMER_PICK_INTERNAL_OLIGO': 0,\n",
    "                'PRIMER_PICK_RIGHT_PRIMER': 1,\n",
    "                'PRIMER_NUM_RETURN': get_number_of_primers(18,36,max_overlap_len),\n",
    "                'PRIMER_OPT_SIZE': 20,\n",
    "                'PRIMER_MIN_SIZE': 18,\n",
    "                'PRIMER_MAX_SIZE': 36,\n",
    "                'PRIMER_OPT_TM': 57.0,\n",
    "                'PRIMER_MIN_TM': 49.5,\n",
    "                'PRIMER_MAX_TM': 64.0,\n",
    "                'PRIMER_MAX_POLY_X' : 8,\n",
    "                'PRIMER_MAX_HAIRPIN_TH' : 10.0,\n",
    "                'PRIMER_MAX_GC' : 90.0,\n",
    "                'PRIMER_MIN_GC' : 1.0,\n",
    "                'PRIMER_PRODUCT_SIZE_RANGE': [coordinates_sequence_template[1]-max_overlap_len,coordinates_sequence_template[1]]\n",
    "            }\n",
    "        ))\n",
    "        pair_list = []\n",
    "        number_of_pairs = int((len(primers)-5)/9)\n",
    "        for i in range(number_of_pairs):\n",
    "            pair_list = pair_list + [{\n",
    "                'PRIMER_LEFT_SEQUENCE' : first_left_primer_sequence,\n",
    "                'PRIMER_RIGHT_SEQUENCE' : primers['PRIMER_RIGHT_'+str(i)+'_SEQUENCE'],\n",
    "                'PRIMER_LEFT_POSITION' : 0,\n",
    "                'PRIMER_RIGHT_POSITION' : primers['PRIMER_RIGHT_'+str(i)][0],\n",
    "                'PRIMER_LEFT_TM': '56',\n",
    "                'PRIMER_RIGHT_TM': primers['PRIMER_RIGHT_'+str(i)+'_TM'],\n",
    "                'PRIMER_PENALTY' : primers['PRIMER_RIGHT_'+str(i)+'_PENALTY']\n",
    "            }]\n",
    "        primers_df = pd.DataFrame(pair_list)\n",
    "        primers_df['PRIMER_RIGHT_POSITION'] = primers_df['PRIMER_RIGHT_POSITION'] + 1\n",
    "        \n",
    "        #In the case of a small region to find primers, we keep at least 80 pb of overlap for the left primer of the next gblock:\n",
    "        primers_df = primers_df.loc[primers_df['PRIMER_RIGHT_POSITION'] > coordinates_sequence_template[0]+min_overlap_len ]\n",
    "        primers_df.sort_values(by='PRIMER_PENALTY', inplace = True)\n",
    "        primers_df.reset_index(inplace=True)\n",
    "        \n",
    "        #Remove primers with GGGG\n",
    "        for idx,pair in primers_df.iterrows():\n",
    "            if 'GGGG' in pair['PRIMER_LEFT_SEQUENCE'] or 'GGGG' in pair['PRIMER_RIGHT_SEQUENCE']:\n",
    "                primers_df.drop(idx, inplace=True)\n",
    "\n",
    "        primers_df.sort_values(by='PRIMER_PENALTY', inplace = True)\n",
    "        primers_df.reset_index(inplace=True)\n",
    "        \n",
    "        #If no primer could be found in right region:\n",
    "        have_no_right_primers = len(primers_df) == 0\n",
    "    \n",
    "        if have_no_right_primers:\n",
    "            index += 1\n",
    "            #peut etre une limite de longueur minimale?\n",
    "            return make_sequencing_primers_rec(seq = seq, fragment_number = fragment_number,coordinates_sequence_template = coordinates_sequence_template, prev = prev,\n",
    "                                                         min_overlap_len = min_overlap_len ,max_overlap_len = max_overlap_len,window_len = window_len,\n",
    "                                                         restricted_region_ordered = restricted_region_ordered, index=index, verbose = verbose, recoil_number = recoil_number,\n",
    "                                                         liste_primers_d = liste_primers_d)\n",
    "        else:\n",
    "            #Change prev for the next iteration:\n",
    "            prev.append(primers_df.loc[0,'PRIMER_RIGHT_POSITION'])\n",
    "            \n",
    "            #initialize recoil_number[fragment_number] if no primers are found:   \n",
    "            if fragment_number > len(recoil_number) -1:\n",
    "                recoil_number.append(0)\n",
    "\n",
    "            #Dictionnary to fill :\n",
    "            primers_d = {\n",
    "                'PRIMER_LEFT_SEQUENCE': first_left_primer_sequence,\n",
    "                'PRIMER_LEFT_POSITION': 0,\n",
    "                'PRIMER_LEFT_TM': '54',\n",
    "                'PRIMER_RIGHT_SEQUENCE': primers_df.loc[0,'PRIMER_RIGHT_SEQUENCE'],\n",
    "                'PRIMER_RIGHT_POSITION': primers_df.loc[0,'PRIMER_RIGHT_POSITION'],\n",
    "                'PRIMER_RIGHT_TM': primers_df.loc[0,'PRIMER_RIGHT_TM'],\n",
    "                'PRIMER_PENALTY' : primers_df.loc[0,'PRIMER_PENALTY']\n",
    "            }\n",
    "            if verbose:print(primers_d)\n",
    "            if verbose:print(type(restricted_region_ordered))\n",
    "            \n",
    "            \n",
    "            if fragment_number > len(liste_primers_d) -1:\n",
    "                liste_primers_d.append(primers_d)\n",
    "            else:\n",
    "                liste_primers_d[fragment_number] = primers_d\n",
    "                \n",
    "            index = 1\n",
    "            fragment_number += 1\n",
    "            \n",
    "            return make_sequencing_primers_rec(seq = seq, fragment_number = fragment_number, coordinates_sequence_template = coordinates_sequence_template, \n",
    "                                                             prev = prev,min_overlap_len = min_overlap_len ,max_overlap_len = max_overlap_len,window_len = window_len, \n",
    "                                                             restricted_region_ordered = restricted_region_ordered, index=1, verbose = verbose, recoil_number = recoil_number,\n",
    "                                                             liste_primers_d = liste_primers_d)\n",
    "             \n",
    "               \n",
    "    # The end\n",
    "    elif (prev[fragment_number] - max_overlap_len + window_len) >= len(seq):\n",
    "        \n",
    "        #if primers_df exist already (notebook iterations might not work in this case):\n",
    "        if verbose:print(\"###\")\n",
    "        if verbose:print(\"###\")\n",
    "        if verbose:print(\"Last gblock\")\n",
    "        if verbose:print(type(liste_primers_d))\n",
    "        if verbose:print(liste_primers_d)\n",
    "        if verbose:print(\"en ordre le type et la liste desiree\")\n",
    "           \n",
    "        last_higher_restricted_border = [int(i.split(\":\")[1]) for i in restricted_region_ordered if prev[fragment_number] > int(i.split(\":\")[1])]\n",
    "\n",
    "        #to make sure no int_64 appears in this list:\n",
    "        prev = [int(i) for i in prev]\n",
    "        #if no restricted area in the last case:\n",
    "        if len(last_higher_restricted_border) == 0:\n",
    "            right_coordinates = [int(prev[fragment_number] - max_overlap_len), int(prev[fragment_number])]\n",
    "\n",
    "       #Depending on the length of the inbetween of 2 restricted regions, 2 cases possible: larger or smaller than max_overlap_len\n",
    "        else:\n",
    "            if  max(last_higher_restricted_border) < int(prev[fragment_number])-max_overlap_len:\n",
    "                right_coordinates = [int(prev[fragment_number] - max_overlap_len), int(prev[fragment_number])]\n",
    "            elif max(last_higher_restricted_border) <= int(prev[fragment_number])-min_overlap_len :\n",
    "                right_coordinates = [int(max(last_higher_restricted_border)),int(prev[fragment_number])]\n",
    "\n",
    "            #Should never respect these conditions: at least 200 bp in the inbetween regions\n",
    "            else:\n",
    "                print(' \"a laide\" **the sad story of a programmer** ')\n",
    "        \n",
    "        if verbose:print('len of last gblock:',len(str(Seq.Seq(seq[right_coordinates[0]:]).reverse_complement())))\n",
    "        if verbose:print('je suis prev[fragment_number] :'+str(prev[fragment_number]))\n",
    "        if verbose:print('right_coordinates : '+str(right_coordinates))\n",
    "        if verbose:print('SEQUENCE_EXCLUDED_REGION : ',[0,len(seq)-prev[fragment_number]])\n",
    "        if verbose:print('PRIMER_PRODUCT_SIZE_RANGE : ',[len(seq)-prev[fragment_number]+min_overlap_len,len(seq)-int(right_coordinates[0])])\n",
    "        #print(str(Seq.Seq(seq[right_coordinates[0]:]).reverse_complement()))\n",
    "        \n",
    "        primers = (primer3.bindings.designPrimers(\n",
    "            {\n",
    "                'SEQUENCE_ID': 'bidon',\n",
    "                'SEQUENCE_TEMPLATE': str(Seq.Seq(seq[right_coordinates[0]:]).reverse_complement()),\n",
    "                'SEQUENCE_EXCLUDED_REGION': [0,len(seq)-prev[fragment_number]],\n",
    "                'SEQUENCE_PRIMER': last_right_primer_sequence_rc\n",
    "            },\n",
    "            {\n",
    "                'PRIMER_TASK': 'generic',\n",
    "                'PRIMER_PICK_LEFT_PRIMER': 0,\n",
    "                'PRIMER_PICK_INTERNAL_OLIGO': 0,\n",
    "                'PRIMER_PICK_RIGHT_PRIMER': 1,\n",
    "                'PRIMER_NUM_RETURN': get_number_of_primers(18,36,max_overlap_len),\n",
    "                'PRIMER_OPT_SIZE': 20,\n",
    "                'PRIMER_MIN_SIZE': 18,\n",
    "                'PRIMER_MAX_SIZE': 36,\n",
    "                'PRIMER_OPT_TM': 57.0,\n",
    "                'PRIMER_MIN_TM': 49.5,\n",
    "                'PRIMER_MAX_TM': 64.0,\n",
    "                'PRIMER_MAX_POLY_X' : 8,\n",
    "                'PRIMER_MAX_HAIRPIN_TH' : 10.0,\n",
    "                'PRIMER_MAX_GC' : 90.0,\n",
    "                'PRIMER_MIN_GC' : 1.0,\n",
    "                'PRIMER_PRODUCT_SIZE_RANGE': [len(seq)-prev[fragment_number]+min_overlap_len,len(seq)-int(right_coordinates[0])]\n",
    "            }\n",
    "        ))\n",
    "        pair_list = []\n",
    "        number_of_pairs = int((len(primers)-5)/9)\n",
    "        for i in range(number_of_pairs):\n",
    "            pair_list = pair_list + [{\n",
    "                'PRIMER_LEFT_SEQUENCE' : str(Seq.Seq(primers['PRIMER_RIGHT_'+str(i)+'_SEQUENCE'])),\n",
    "                'PRIMER_RIGHT_SEQUENCE' : last_right_primer_sequence_rc,\n",
    "                'PRIMER_LEFT_POSITION' : ((len(seq[right_coordinates[0]:]))-(int(primers['PRIMER_RIGHT_'+str(i)][0])+1)),\n",
    "                'PRIMER_RIGHT_POSITION' : len(seq),\n",
    "                'PRIMER_LEFT_TM': primers['PRIMER_RIGHT_'+str(i)+'_TM'],\n",
    "                'PRIMER_RIGHT_TM': '57',\n",
    "                'PRIMER_PENALTY' : primers['PRIMER_RIGHT_'+str(i)+'_PENALTY']\n",
    "            }]\n",
    "\n",
    "        primers_df = pd.DataFrame(pair_list)\n",
    "        primers_df['PRIMER_LEFT_POSITION'] = primers_df['PRIMER_LEFT_POSITION'] + right_coordinates[0]\n",
    "        primers_df = primers_df.loc[primers_df['PRIMER_LEFT_POSITION'] < prev[fragment_number] - min_overlap_len]\n",
    "        primers_df.sort_values(by='PRIMER_PENALTY', inplace = True)\n",
    "        primers_df.reset_index(inplace=True)\n",
    "        \n",
    "        # Remove primers with GGGG\n",
    "        for idx,pair in primers_df.iterrows():\n",
    "            if 'GGGG' in pair['PRIMER_LEFT_SEQUENCE'] or 'GGGG' in pair['PRIMER_RIGHT_SEQUENCE']:\n",
    "                primers_df.drop(idx, inplace=True)\n",
    "\n",
    "        primers_df.sort_values(by='PRIMER_PENALTY', inplace = True)\n",
    "        primers_df.reset_index(inplace=True)\n",
    "        \n",
    "        have_no_left_primers = len(primers_df) == 0\n",
    "        \n",
    "        if have_no_left_primers:\n",
    "            fragment_number -= 1\n",
    "            prev = prev[:-1]\n",
    "            index = 2+recoil_number[fragment_number]\n",
    "            recoil_number[fragment_number] += 1\n",
    "            return make_sequencing_primers_rec(seq = seq, fragment_number = fragment_number,coordinates_sequence_template = coordinates_sequence_template, prev = prev,\n",
    "                                                    min_overlap_len = min_overlap_len ,max_overlap_len = max_overlap_len,window_len = window_len,\n",
    "                                                    restricted_region_ordered = restricted_region_ordered, index=index, verbose = verbose, recoil_number = recoil_number,\n",
    "                                                    liste_primers_d = liste_primers_d)\n",
    "        \n",
    "        else:                    \n",
    "            primers_d = {\n",
    "                'PRIMER_LEFT_SEQUENCE': primers_df.loc[0,'PRIMER_LEFT_SEQUENCE'],\n",
    "                'PRIMER_LEFT_POSITION': primers_df.loc[0,'PRIMER_LEFT_POSITION'],\n",
    "                'PRIMER_LEFT_TM': primers_df.loc[0,'PRIMER_LEFT_TM'],\n",
    "                'PRIMER_RIGHT_SEQUENCE': last_right_primer_sequence_rc,\n",
    "                'PRIMER_RIGHT_POSITION': len(seq),\n",
    "                'PRIMER_RIGHT_TM': '57',\n",
    "                'PRIMER_PENALTY' : primers_df.loc[0,'PRIMER_PENALTY']\n",
    "            }\n",
    "            if verbose:print(primers_d)\n",
    "            if fragment_number > len(liste_primers_d) -1:\n",
    "                liste_primers_d.append(primers_d)\n",
    "            else:\n",
    "                liste_primers_d[fragment_number] = primers_d\n",
    "\n",
    "            return liste_primers_d\n",
    "        \n",
    "    \n",
    "    \n",
    "#For the general case:\n",
    "    else:\n",
    "        #if no restricted region:\n",
    "        last_higher_restricted_border = [int(i.split(\":\")[1]) for i in restricted_region_ordered if prev[fragment_number] > int(i.split(\":\")[1])]\n",
    "        if last_higher_restricted_border:\n",
    "            if verbose:print(\"max of last higher restriced border: \", max(last_higher_restricted_border))\n",
    "        \n",
    "        #if no restricted area in the last case:\n",
    "        if len(last_higher_restricted_border) == 0:\n",
    "            left_coordinates = [int(prev[fragment_number] - max_overlap_len), int(prev[fragment_number])]\n",
    "\n",
    "       #Depending on the length of the inbetween of 2 restricted regions, 2 cases possible: larger or smaller than max_overlap_len\n",
    "        else:\n",
    "            if max(last_higher_restricted_border) < int(prev[fragment_number])-max_overlap_len:\n",
    "                left_coordinates = [int(prev[fragment_number] - max_overlap_len), int(prev[fragment_number])]\n",
    "            elif max(last_higher_restricted_border) <= int(prev[fragment_number])-min_overlap_len :\n",
    "                left_coordinates = [int(max(last_higher_restricted_border)),int(prev[fragment_number])]\n",
    "\n",
    "            #Should never respect these conditions: at least min_overlap bp in the inbetween of restricted regions\n",
    "            else:\n",
    "                print(' **1the sad story of a programmer** ')\n",
    "\n",
    "        #Find the right place:\n",
    "        coordinates_sequence_template = find_right_coordinates(index,restricted_region_ordered,max_overlap_len,window_len,prev[fragment_number],left_coordinates[0],verbose)\n",
    "        current_coordinates_sequence_template = [int(element) for element in coordinates_sequence_template]\n",
    "        if verbose:print(current_coordinates_sequence_template)\n",
    "\n",
    "        prev[fragment_number]=int(prev[fragment_number])\n",
    "        if verbose:print('je suis prev[fragment_number] :'+str(prev[fragment_number]))\n",
    "        if verbose:print('je suis current_sequence_template : '+str(current_coordinates_sequence_template))\n",
    "\n",
    "        if verbose:print('left_coordinates : '+str(left_coordinates))\n",
    "        if verbose:print('current_coordinates_sequence_template : '+str(current_coordinates_sequence_template))\n",
    "#         print('SEQUENCE_TEMPLATE : '+ str(seq[left_coordinates[0]:current_coordinates_sequence_template[1]]))\n",
    "        if verbose:print('SEQUENCE_EXCLUDED_REGION : '+str(prev[fragment_number]-left_coordinates[0])+', '+str(current_coordinates_sequence_template[0]-prev[fragment_number]))\n",
    "        if verbose:print('PRIMER_PRODUCT_SIZE_RANGE : '+ str(current_coordinates_sequence_template[0]-left_coordinates[1])+', '+str(current_coordinates_sequence_template[1] - left_coordinates[0]))\n",
    "\n",
    "        primers = (primer3.bindings.designPrimers(\n",
    "            {\n",
    "                'SEQUENCE_ID': 'bidon',\n",
    "                'SEQUENCE_TEMPLATE': str(seq[left_coordinates[0]:current_coordinates_sequence_template[1]]),\n",
    "                'SEQUENCE_EXCLUDED_REGION':[prev[fragment_number]-left_coordinates[0], \n",
    "                                            current_coordinates_sequence_template[0]-prev[fragment_number]]\n",
    "            },\n",
    "            {\n",
    "                'PRIMER_TASK': 'generic',\n",
    "                'PRIMER_PICK_LEFT_PRIMER': 1,\n",
    "                'PRIMER_PICK_INTERNAL_OLIGO': 0,\n",
    "                'PRIMER_PICK_RIGHT_PRIMER': 1,\n",
    "                'PRIMER_NUM_RETURN': get_number_of_primers(18,36,max_overlap_len)*2,\n",
    "                'PRIMER_OPT_SIZE': 20,\n",
    "                'PRIMER_MIN_SIZE': 18,\n",
    "                'PRIMER_MAX_SIZE': 36,\n",
    "                'PRIMER_OPT_TM': 57.0,\n",
    "                'PRIMER_MIN_TM': 49.5,\n",
    "                'PRIMER_MAX_TM': 64.0,\n",
    "                'PRIMER_MAX_POLY_X' : 8,\n",
    "                'PRIMER_MAX_HAIRPIN_TH' : 10.0,\n",
    "                'PRIMER_MAX_GC' : 90.0,\n",
    "                'PRIMER_MIN_GC' : 1.0,\n",
    "                'PRIMER_PRODUCT_SIZE_RANGE': [current_coordinates_sequence_template[0]-prev[fragment_number]-min_overlap_len , \n",
    "                                              current_coordinates_sequence_template[1]-left_coordinates[0]]\n",
    "            }\n",
    "        ))\n",
    "\n",
    "        primers_df = primer_dict_to_df(primers)            \n",
    "        primers_df['PRIMER_LEFT_POSITION'] = primers_df['PRIMER_LEFT_POSITION'] + left_coordinates[0]\n",
    "        primers_df['PRIMER_RIGHT_POSITION'] = primers_df['PRIMER_RIGHT_POSITION'] + left_coordinates[0] + 1\n",
    "\n",
    "        #remove primers with GGGG:\n",
    "        for idx,pair in primers_df.iterrows():\n",
    "            if 'GGGG' in pair['PRIMER_LEFT_SEQUENCE'] or 'GGGG' in pair['PRIMER_RIGHT_SEQUENCE']:\n",
    "                primers_df.drop(idx, inplace=True)      \n",
    "        primers_df.sort_values(by='PRIMER_PENALTY', inplace = True)\n",
    "        primers_df.reset_index(inplace=True)\n",
    "        \n",
    "        #Make the verification df:\n",
    "        have_no_right_primers = len(primers_df.loc[primers_df['PRIMER_RIGHT_POSITION'] > current_coordinates_sequence_template[0]+min_overlap_len]) == 0\n",
    "        have_no_left_primers = len(primers_df.loc[primers_df['PRIMER_LEFT_POSITION'] < prev[fragment_number] - min_overlap_len]) == 0\n",
    "        primers_df = primers_df.loc[(primers_df['PRIMER_RIGHT_POSITION'] > current_coordinates_sequence_template[0]+min_overlap_len) & \n",
    "            (primers_df['PRIMER_LEFT_POSITION'] < prev[fragment_number] - min_overlap_len)]\n",
    "\n",
    "        primers_df.sort_values(by='PRIMER_PENALTY', inplace = True)\n",
    "        primers_df.reset_index(inplace=True)\n",
    "        \n",
    "        have_no_pairs = len(primers_df) == 0\n",
    "        \n",
    "        if verbose:print('len of primers_df:',len(primers_df))\n",
    "        \n",
    "        if have_no_right_primers:\n",
    "            index += 1\n",
    "            #peut etre une limite de longueur minimale?\n",
    "            return make_sequencing_primers_rec(seq = seq, fragment_number = fragment_number,coordinates_sequence_template = coordinates_sequence_template, prev = prev,\n",
    "                                                         min_overlap_len = min_overlap_len ,max_overlap_len = max_overlap_len,window_len = window_len,\n",
    "                                                         restricted_region_ordered = restricted_region_ordered, index=index, verbose = verbose, recoil_number = recoil_number,\n",
    "                                                         liste_primers_d = liste_primers_d)\n",
    "        elif have_no_left_primers or have_no_pairs:\n",
    "            if verbose:print(\"je suis fragment number\")\n",
    "            if verbose:print(fragment_number)\n",
    "            if verbose:print(\"je suis recoil_number :) \")\n",
    "            if verbose:print(recoil_number)\n",
    "            fragment_number -= 1\n",
    "            prev = prev[:-1]\n",
    "            index = 2+recoil_number[fragment_number]\n",
    "            #print(\"je suis index apres recoil_number : \"+str(index))\n",
    "            recoil_number[fragment_number] += 1\n",
    "            return make_sequencing_primers_rec(seq = seq, fragment_number = fragment_number,coordinates_sequence_template = coordinates_sequence_template, prev = prev,\n",
    "                                                    min_overlap_len = min_overlap_len ,max_overlap_len = max_overlap_len,window_len = window_len,\n",
    "                                                    restricted_region_ordered = restricted_region_ordered, index=index, verbose = verbose, recoil_number = recoil_number, \n",
    "                                                    liste_primers_d = liste_primers_d)\n",
    "\n",
    "        else :\n",
    "            if verbose:print('primer_df apres filtres')\n",
    "            if verbose:print(primers_df)\n",
    "            \n",
    "\n",
    "            #Add the primer right position as prev[fragment_number] in prev:\n",
    "            prev.append(primers_df.loc[0,'PRIMER_RIGHT_POSITION'])\n",
    "            \n",
    "            #initialize recoil_number[fragment_number] if no primers are found:   \n",
    "            if fragment_number > len(recoil_number) -1:\n",
    "                recoil_number.append(0)\n",
    "\n",
    "            primers_d = {\n",
    "                'PRIMER_LEFT_SEQUENCE': primers_df.loc[0,'PRIMER_LEFT_SEQUENCE'],\n",
    "                'PRIMER_LEFT_POSITION': primers_df.loc[0,'PRIMER_LEFT_POSITION'],\n",
    "                'PRIMER_LEFT_TM': primers_df.loc[0,'PRIMER_LEFT_TM'],\n",
    "                'PRIMER_RIGHT_SEQUENCE': primers_df.loc[0,'PRIMER_RIGHT_SEQUENCE'],\n",
    "                'PRIMER_RIGHT_POSITION': primers_df.loc[0,'PRIMER_RIGHT_POSITION'],\n",
    "                'PRIMER_RIGHT_TM': primers_df.loc[0,'PRIMER_RIGHT_TM'],\n",
    "                'PRIMER_PENALTY' : primers_df.loc[0,'PRIMER_PENALTY']\n",
    "            }\n",
    "            \n",
    "            if fragment_number > len(liste_primers_d) -1:\n",
    "                liste_primers_d.append(primers_d)\n",
    "            else:\n",
    "                liste_primers_d[fragment_number] = primers_d\n",
    "                \n",
    "            index = 1\n",
    "            fragment_number += 1\n",
    "#             print(prev)\n",
    "#             print(fragment_number)\n",
    "#             print(coordinates_sequence_template)\n",
    "            return make_sequencing_primers_rec(seq = seq, fragment_number = fragment_number,coordinates_sequence_template = coordinates_sequence_template, prev = prev,\n",
    "                                                             min_overlap_len = min_overlap_len ,max_overlap_len = max_overlap_len,window_len = window_len,\n",
    "                                                             restricted_region_ordered = restricted_region_ordered, index=index, verbose = verbose, recoil_number =  recoil_number,\n",
    "                                                            liste_primers_d = liste_primers_d)\n",
    "# # start_time = time.time()\n",
    "# # print(fasta)\n",
    "# # print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# # print(primer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "          \n",
    "      \n",
    "INPUT SECTION:\n",
    "    \n",
    "    \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primer_df deleted\n"
     ]
    }
   ],
   "source": [
    "# #last primer most be specify (because this primer is suboptimal and primer3 might not find it)\n",
    "# #must be REVERSE COMPLEMENT with _rc option, foward if no _rc suffix:\n",
    "#last_right_primer_sequence = \"AACATCCAATAAATCATACAGGCAAG\"\n",
    "last_right_primer_sequence = \"GACCGCTACACTTGCCAG\".upper()\n",
    "last_right_primer_sequence_rc = \"CTGGCAAGTGTAGCGGTC\".upper()\n",
    "\n",
    "#first primer most be specify (because this primer is suboptimal and primer3 might not find it)\n",
    "first_left_primer_sequence = \"GCTATCGCTATGTTTTCAAGGA\"\n",
    "\n",
    "#Delete primer_df at first if it exists:\n",
    "if 'primer_df' in locals():\n",
    "    print(\"primer_df deleted\")\n",
    "    del primer_df\n",
    "\n",
    "#Set the parameters to run the above cell:\n",
    "Version = 1\n",
    "file_name_fasta = \"../ref_files_m13/m13_ref_rbs/splitter_gblock4.fa\"\n",
    "\n",
    "#file_name_gff = \"../meso/mfl_recoding/data/official_files/recnref_L1_seed_is_idx.v7.it4.gff3\"\n",
    "ref_fasta_file = str(SeqIO.read(file_name_fasta, \"fasta\").seq).upper()\n",
    "circular = False\n",
    "\n",
    "if circular:\n",
    "    #for circular construction.\n",
    "    ref_fasta_file = (first_left_primer_sequence+ref_fasta_file.split(first_left_primer_sequence)[1])+ref_fasta_file.split(last_right_primer_sequence)[0]+str(last_right_primer_sequence)\n",
    "\n",
    "#######PARAMETERS FOR THE CODE###############\n",
    "official_restricted_region_list = []\n",
    "prev = [0]            #keep this parameter to [0] (really important)\n",
    "coordinates_sequence_template = []\n",
    "index = 1           #keep this parameter to 1 (really important)\n",
    "fragment_number = 0\n",
    "min_overlap_len = 40\n",
    "max_overlap_len = 80\n",
    "window_len = 780\n",
    "is_starting = True\n",
    "verbose = True      #would u like to have more information while it is runnning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make primers (and cut 40 kb into gblocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "official_restricted_region_list : []\n",
      "0\n",
      "le fragment_number n'est pas bien initialise, mais nous avons corrige le tir\n",
      "la liste_primers_d n'est pas bien initialisee, mais nous avons corrige le tir\n",
      "1 fois!\n",
      "je suis toutes les zones pouvant accueillir des primers: [[780, 860]]\n",
      "je suis tous les places possibles pour accueillir des primers: [[780, 860]]\n",
      "je suis coordinates_sequence_template : [780, 860]\n",
      "current_coordinates_sequence_template : [780, 860]\n",
      "type de current_coordinates_sequence_template : <class 'int'>\n",
      "{'PRIMER_LEFT_SEQUENCE': 'GCTATCGCTATGTTTTCAAGGA', 'PRIMER_LEFT_POSITION': 0, 'PRIMER_LEFT_TM': '54', 'PRIMER_RIGHT_SEQUENCE': 'TATTAACACCGCCTGCAACA', 'PRIMER_RIGHT_POSITION': 860, 'PRIMER_RIGHT_TM': 57.813467971597504, 'PRIMER_PENALTY': 0.813467971597504}\n",
      "<class 'list'>\n",
      "1\n",
      "###\n",
      "###\n",
      "Last gblock\n",
      "<class 'list'>\n",
      "[{'PRIMER_LEFT_SEQUENCE': 'GCTATCGCTATGTTTTCAAGGA', 'PRIMER_LEFT_POSITION': 0, 'PRIMER_LEFT_TM': '54', 'PRIMER_RIGHT_SEQUENCE': 'TATTAACACCGCCTGCAACA', 'PRIMER_RIGHT_POSITION': 860, 'PRIMER_RIGHT_TM': 57.813467971597504, 'PRIMER_PENALTY': 0.813467971597504}]\n",
      "en ordre le type et la liste desiree\n",
      "len of last gblock: 727\n",
      "je suis prev[fragment_number] :860\n",
      "right_coordinates : [780, 860]\n",
      "SEQUENCE_EXCLUDED_REGION :  [0, 647]\n",
      "PRIMER_PRODUCT_SIZE_RANGE :  [687, 727]\n",
      "{'PRIMER_LEFT_SEQUENCE': 'TGAGGTTCAGCAAGGTGAT', 'PRIMER_LEFT_POSITION': 780, 'PRIMER_LEFT_TM': 56.23657042401186, 'PRIMER_RIGHT_SEQUENCE': 'CTGGCAAGTGTAGCGGTC', 'PRIMER_RIGHT_POSITION': 1507, 'PRIMER_RIGHT_TM': '57', 'PRIMER_PENALTY': 1.763429575988141}\n",
      "     PRIMER_LEFT_SEQUENCE  PRIMER_LEFT_POSITION PRIMER_LEFT_TM  \\\n",
      "0  GCTATCGCTATGTTTTCAAGGA                     0             54   \n",
      "1     TGAGGTTCAGCAAGGTGAT                   780        56.2366   \n",
      "\n",
      "  PRIMER_RIGHT_SEQUENCE  PRIMER_RIGHT_POSITION PRIMER_RIGHT_TM  PRIMER_PENALTY  \n",
      "0  TATTAACACCGCCTGCAACA                    860         57.8135        0.813468  \n",
      "1    CTGGCAAGTGTAGCGGTC                   1507              57        1.763430  \n"
     ]
    }
   ],
   "source": [
    "#create official restricted region\n",
    "\n",
    "official_restricted_region_list = []\n",
    "if verbose:print(\"official_restricted_region_list :\",official_restricted_region_list)\n",
    "\n",
    "primer_df = pd.DataFrame(make_sequencing_primers_rec(ref_fasta_file,fragment_number,coordinates_sequence_template,prev,min_overlap_len,\n",
    "                                                    max_overlap_len,window_len,official_restricted_region_list,index,is_starting,verbose))\n",
    "print(primer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['None', 'TGAGGTTCAGCAAGGTGATGCTTTAGATTTTTCATTTGCTGCTGGCTCTCAGCGTGGCACTGTTGCAGGCGGTGTTAATA']\n",
      "     PRIMER_LEFT_SEQUENCE  PRIMER_LEFT_POSITION PRIMER_LEFT_TM  \\\n",
      "0  GCTATCGCTATGTTTTCAAGGA                     0             54   \n",
      "1     TGAGGTTCAGCAAGGTGAT                   780        56.2366   \n",
      "\n",
      "  PRIMER_RIGHT_SEQUENCE  PRIMER_RIGHT_POSITION PRIMER_RIGHT_TM  \\\n",
      "0  TATTAACACCGCCTGCAACA                    860         57.8135   \n",
      "1    CTGGCAAGTGTAGCGGTC                   1507              57   \n",
      "\n",
      "   PRIMER_PENALTY  IS_LEFT_SAME  IS_RIGHT_SAME  \\\n",
      "0        0.813468          True           True   \n",
      "1        1.763430          True           True   \n",
      "\n",
      "                                         overlap_seq  overlap_length  \\\n",
      "0                                               None               0   \n",
      "1  TGAGGTTCAGCAAGGTGATGCTTTAGATTTTTCATTTGCTGCTGGC...              80   \n",
      "\n",
      "     perc_GC  amplicon_len                                   g_block_sequence  \n",
      "0  33.953488           860  GCTATCGCTATGTTTTCAAGGATTCTAAGGGAAAATTAATTAATAG...  \n",
      "1  45.667125           727  TGAGGTTCAGCAAGGTGATGCTTTAGATTTTTCATTTGCTGCTGGC...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "####################################################################################\n",
    "#Verifier si des positions sont dans un intervalle de restricted_region_ordered\n",
    "for element in list(official_restricted_region_list):\n",
    "    gauche = int(element.split(':')[0])\n",
    "    droite = int(element.split(':')[1])\n",
    "    for number,positions_primers_droits in enumerate(primer_df['PRIMER_RIGHT_POSITION']):\n",
    "        if gauche < positions_primers_droits and positions_primers_droits < droite:\n",
    "            print('primer in restricted regions right')\n",
    "            print(gauche,droite,positions_primers_droits)\n",
    "#             print(primer_dfs[iteration]['PRIMER_RIGHT_POSITION'])\n",
    "    for number,positions_primers_gauches in enumerate(primer_df['PRIMER_LEFT_POSITION']):\n",
    "        if gauche < positions_primers_gauches and positions_primers_gauches < droite:\n",
    "            print('primer in restricted regions left')\n",
    "    #If nothing is written, none of the primers are in restricted region!\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "#Confirm primer's sequence\n",
    "primer_df['seq_s'] = \"\"\n",
    "primer_df['seq_e'] = \"\"\n",
    "primer_df['overlap_length'] = 0\n",
    "\n",
    "for idx, pair in primer_df.iterrows():\n",
    "    primer_df.loc[idx,'seq_s'] = str(ref_fasta_file[int(pair['PRIMER_LEFT_POSITION']):int(pair['PRIMER_LEFT_POSITION'])+len(pair['PRIMER_LEFT_SEQUENCE'])])\n",
    "    primer_df.loc[idx,'seq_e'] = str(Seq.Seq(ref_fasta_file[int(pair['PRIMER_RIGHT_POSITION'])-len(pair['PRIMER_RIGHT_SEQUENCE']):int(pair['PRIMER_RIGHT_POSITION'])]).reverse_complement())\n",
    "\n",
    "primer_df['amplicon_len'] = primer_df['PRIMER_RIGHT_POSITION'] - primer_df['PRIMER_LEFT_POSITION'] #+16\n",
    "primer_df['IS_LEFT_SAME'] = primer_df['PRIMER_LEFT_SEQUENCE'] == primer_df['seq_s']\n",
    "primer_df['IS_RIGHT_SAME'] = primer_df['PRIMER_RIGHT_SEQUENCE'] == primer_df['seq_e']\n",
    "\n",
    "for idx, pair in primer_df.iterrows():\n",
    "    if idx == 0 and circular:\n",
    "        primer_df.loc[idx,'overlap_length'] = len(first_left_primer_sequence+ref_fasta_file.split(first_left_primer_sequence)[1].split(last_right_primer_sequence)[0]+last_right_primer_sequence)\n",
    "    elif idx == 0:\n",
    "        primer_df.loc[idx,'overlap_length'] = 0\n",
    "    else:\n",
    "        primer_df.loc[idx,'overlap_length'] = primer_df.loc[idx-1,'PRIMER_RIGHT_POSITION'] - primer_df.loc[idx,'PRIMER_LEFT_POSITION']\n",
    "\n",
    "#primer_df.to_csv(path_or_buf=\"../data/official_files/primerdf_\"+str(Version)+\".tsv\",sep=\"\\t\",index=False)\n",
    "\n",
    "#print(primer_df[['PRIMER_PENALTY','IS_LEFT_SAME','IS_RIGHT_SAME']])\n",
    "    \n",
    "####################################################################################\n",
    "#Write output\n",
    "g_block_sequence_list = []\n",
    "overlap_seq_list = []\n",
    "\n",
    "#Create all the g-block\n",
    "for idx,i in enumerate(primer_df[\"PRIMER_RIGHT_POSITION\"]):\n",
    "    g_block_sequence_list.append(str(ref_fasta_file[int(primer_df['PRIMER_LEFT_POSITION'][idx]):int(primer_df['PRIMER_RIGHT_POSITION'][idx])]))\n",
    "\n",
    "#Find the overlaps_length between each g-block:\n",
    "#Create the column overlap_seq :\n",
    "if circular:\n",
    "    overlap_seq_list.append(first_left_primer_sequence+ref_fasta_file.split(first_left_primer_sequence)[1].split(last_right_primer_sequence)[0]+last_right_primer_sequence)\n",
    "else:\n",
    "    overlap_seq_list.append(\"None\")\n",
    "    \n",
    "for num, g_block in enumerate(g_block_sequence_list):\n",
    "    if num < len(g_block_sequence_list) -1 :\n",
    "        overlap_seq_list.append(str(ref_fasta_file[primer_df['PRIMER_LEFT_POSITION'][num+1]:primer_df['PRIMER_RIGHT_POSITION'][num]]))\n",
    "print(overlap_seq_list)\n",
    "# file_name_fasta = \"../meso/mfl_recoding/data/official_files/recnref_L1_seed_is_idx.v7.it4.fa\"\n",
    "# file_name_gff = \"../meso/mfl_recoding/data/official_files/recnref_L1_seed_is_idx.v7.it4.gff3\"\n",
    "\n",
    "\n",
    "#.tsv resume file for recnref:\n",
    "#annotation_df = get_annotation_df_from_gff3(\"../meso/mfl_recoding/data/L1.fa\",\n",
    "                                                   #file_name_gff,\n",
    "                                                   #file_name_fasta)\n",
    "# total_features = []\n",
    "# for idx, pair in primer_df.iterrows():\n",
    "#     features_in_gblock = []\n",
    "#     for nombre, element in annotation_df.iterrows(): \n",
    "#         if primer_df['PRIMER_RIGHT_POSITION'][idx] > annotation_df[\"start\"][nombre] and primer_df['PRIMER_LEFT_POSITION'][idx] < annotation_df[\"end\"][nombre] and nombre < len(annotation_df) -1:\n",
    "#             nombre = nombre+1\n",
    "#             features_in_gblock.append(annotation_df[\"name\"][nombre].replace(\" \", \"\"))\n",
    "#     total_features.append(features_in_gblock)\n",
    "\n",
    "#calculate the % GC for each g_block\n",
    "perc_GC = [(GC(G_block)) for G_block in g_block_sequence_list]\n",
    "primer_df['perc_GC'] = pd.Series(perc_GC)\n",
    "#primer_df[\"features_in_gblock\"] = pd.Series([element for element in total_features])\n",
    "primer_df[\"g_block_sequence\"] = pd.Series([element for element in g_block_sequence_list])\n",
    "primer_df[\"overlap_seq\"] = pd.Series(overlap_seq_list)\n",
    "\n",
    "col_to_delete = ['seq_s','seq_e']\n",
    "for element in col_to_delete:\n",
    "    try:\n",
    "        del primer_df[element]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "primer_df = primer_df[['PRIMER_LEFT_SEQUENCE', 'PRIMER_LEFT_POSITION', 'PRIMER_LEFT_TM'\n",
    "                               , 'PRIMER_RIGHT_SEQUENCE', 'PRIMER_RIGHT_POSITION','PRIMER_RIGHT_TM', 'PRIMER_PENALTY'\n",
    "                               ,'IS_LEFT_SAME', 'IS_RIGHT_SAME','overlap_seq', 'overlap_length',\"perc_GC\",'amplicon_len','g_block_sequence']]\n",
    "\n",
    "more_than_40GC = primer_df.loc[(primer_df['perc_GC'] >= 40) & (primer_df['perc_GC'] <= 60)]\n",
    "less_than_40GC = primer_df.loc[(primer_df['perc_GC'] < 40)]\n",
    "\n",
    "print(primer_df)\n",
    "\n",
    "#.tsv resume file for recoded:\n",
    "primer_df.to_csv(\"../ref_files_m13/m13_ref_rbs/\"+str(window_len)+\n",
    "                 \"minhomo_\"+str(min_overlap_len)+\"maxhomo_\"+str(max_overlap_len)+\"_IDT.tsv\", sep=\"\\t\", index = False)\n",
    "\n",
    "#make a fasta file of all fragment to test them in idtdna:\n",
    "with open(\"../ref_files_m13/m13_ref_rbs/\"+str(window_len)+\"minhomo_\"+str(min_overlap_len)+\"maxhomo_\"+str(max_overlap_len)+\"_IDT.fa\", 'w') as fout:\n",
    "    string = \"\"\n",
    "    for i,seq in enumerate(primer_df[\"g_block_sequence\"]):\n",
    "        string+=\">\"+str(i)+\"\\n\"+str(seq)+\"\\n\"\n",
    "    fout.write(string)\n",
    "\n",
    "#make a fasta file to test if overlap sequences have homology with each other:\n",
    "with open(\"../ref_files_m13/m13_ref_rbs/splitter_gblock4_\"+str(window_len)+\"minhomo_\"+str(min_overlap_len)+\"maxhomo_\"+str(max_overlap_len)+\"_overlaps.fa\", 'w') as fout:\n",
    "    string = \"\"\n",
    "    for i,seq in enumerate(primer_df[\"overlap_seq\"]):\n",
    "        string+=\">\"+str(i)+\"\\n\"+str(seq)+\"\\n\"\n",
    "    fout.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../meso/mfl_recoding/data/official_files/codex/first_tests/18.it0.wlen920minhomo_40maxhomo_80_CODEX.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e1169ecf8394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Make a graph of the overlap distributions:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../meso/mfl_recoding/data/official_files/codex/first_tests/18.it0.wlen920minhomo_40maxhomo_80_CODEX.tsv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprimer_df\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimer_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overlap_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprimer_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overlap_length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Overlap distribution'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../meso/mfl_recoding/data/official_files/codex/first_tests/18.it0.wlen920minhomo_40maxhomo_80_CODEX.tsv'"
     ]
    }
   ],
   "source": [
    "#Make a graph of the overlap distributions:\n",
    "filename = \"../meso/mfl_recoding/data/official_files/codex/first_tests/18.it0.wlen920minhomo_40maxhomo_80_CODEX.tsv\"\n",
    "primer_df =  pd.read_csv(filename, sep='\\t')\n",
    "plt.hist(primer_df['overlap_length'][primer_df['overlap_length'] > 0])\n",
    "plt.title('Overlap distribution')\n",
    "plt.xlabel('overlap length (bp)')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n",
    "\n",
    "#Make a graph of gblock_length:\n",
    "plt.hist(primer_df['amplicon_len'], color = 'red')\n",
    "plt.title('Amplicon length distribution')\n",
    "plt.xlabel('Amplicon length (bp)')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n",
    "\n",
    "#Make a graph of overlap_len:\n",
    "plt.hist(primer_df['overlap_length'], color = 'darkgreen')\n",
    "plt.title('overlap_length distribution')\n",
    "plt.xlabel('overlap_length (bp)')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n",
    "\n",
    "#Make a graph of the tm distribution: NOT A CUTE GRAPH ... AND NOT REALLY USEFULL TOO\n",
    "right_array = [element for count,element in enumerate(primer_df['PRIMER_RIGHT_TM']) if count+1 != len(primer_df['PRIMER_RIGHT_TM'])]\n",
    "left_array = [element for count,element in enumerate(primer_df['PRIMER_LEFT_TM']) if count+1 != len(primer_df['PRIMER_LEFT_TM'])]\n",
    "sns.distplot(right_array, kde=False, color=\"orange\", )\n",
    "sns.distplot(left_array, kde=False, color=\"blue\")\n",
    "plt.title('distribution of Tm of primers')\n",
    "plt.xlabel('Tm of primers')\n",
    "plt.ylabel('count')\n",
    "# plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "#Make a graph of primer_penalty_distribution:\n",
    "sns.distplot([penalty for penalty in primer_df['PRIMER_PENALTY']], kde=False, color=\"cyan\")\n",
    "plt.title('distribution of penalty for each primer pair')\n",
    "plt.xlabel('penalty of primers')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n",
    "\n",
    "#Make a graph of %GC distribution of every fragments:\n",
    "plt.hist(primer_df['perc_GC'], color = 'brown')\n",
    "plt.title('distribution of %GC of each fragments')\n",
    "plt.xlabel('%GC')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AACGCTACTACTATTAGTAGAATTGATGCCACCTTTTCAGCTCGCGCCCCAAATGAAAATATAGCTAAACAGGTTATTGACCATTTGCGAAATGTATCTAATGGTCAAACTAAATCTACTCGTTCGCAGAATTGGGAATCAACTGTTACATGGAATGAAACTTCCAGACACCGTACTTTAGTTGCATATTTAAAACATGTTGAGCTACAGCACCAGATTCAGCAATTAAGCTCTAAGCCATCCGCAAAAATGACCTCTTATCAAAAGGAGCAATTAAAGGTACTCTCTAATCCTGACCTGTTGGAGTTTGCTTCCGGTCTGGTTCGCTTTGAAGCTCGAATTAAAACGCGATATTTGAAGTCTTTCGGGCTTCCTCTTAACCTCTTTGATGCTATCCGCTTTGCTTCTGACTACAACAGTCAGGGTAAAGACCTGATTTTTGATTTATGGTCATTCTCGTTTTCTGAACTGTTTAAAGCATTTGAGGGGGATTCAATGAATATTTATGACGATTCCGCAGTATTGGACGCTATCCAGTCTAAACATTTTACTATTACCCCCTCTGGCAAAACTTCTTTTGCAAAAGCCTCTCGCTATTTTGGTTTTTATCGTCGTCTGGTAAACGAGGGTTATGATAGTGTTGCTCTTACTATGCCTCGTAATTCCTTTTGGCGTTATGTATCTGCATTAGTTGAATGTGGTATTCCTAAATCTCAACTGATGAATCTTTCTACCTGTAATAATGTTGTTCCGTTAGTTCGTTTTATTAACGTAGATTTCAGCTCCCAACGTCCTGACTGGTACAATGAGCCCGTTCTTAAAATCGCATAAGGTAATTCACAATGATTAAAGTTGAAATTAAACCATCTCAAGCCCAATTTACTACTCGTTCTGGTGTTTCTCGTCAGGGCAAGCCTTATTCACTGAATGAGCAGCTTTGTTACGTTGATTTGGGTAATGAATATCCGGTTCTTGTCAAGATTACTCTTGATGAAGGTCAGCCAGCCTATGCGCCTGGTCTGTACACCGTTCATCTGTCCTCTTTCAAAGTTGGTCAGTTCGGTTCCCTTATGATTGACCGTCTGCGCCTCGTTCCGGCTAAGTAACATGGAGCAGGTCGCGGATTTCGACACAATTTATCAGGCGATGATACAAATCTCCGTTGTACTTTGTTTCGCGCTTGGTATAATCGCTGGGGGTCAAAGATGAGTGTTTTAGTGTATTCTTTCGCCTCTTTCGTTTTAGGTTGGTGCCTTCGTAGTGGCATTACGTATTTTACCCGTTTAATGGAAACTTCCTCATGAAAAAGTCTTTAGTCCTCAAAGCCTCTGTAGCCGTTGCTACCCTCGTTCCGATGCTGTCTTTCGCTGCTGAGGGTGACGATCCCGCAAAAGCGGCCTTTAACTCCCTGCAAGCCTCAGCGACCGAATATATCGGTTATGCGTGGGCGATGGTTGTTGTCATTGTCGGCGCAACTATCGGTATCAAGCTGTTTAAGAAATTCACCTCGAAAGCAAGCTGATAAACCGATACAATTAAAGGCTCCTTTTGGAGCCTTTTTTTTTGGAGATTTTCAACGTGAAAAAATTATTATTCGCAATTCCTTTAGTTGTTCCTTTCTATTCTCACTCCGCTGAAACTGTTGAAAGTTGTTTAGCAAAACCCCATACAGAAAATTCATTTACTAACGTCTGGAAAGACGACAAAACTTTAGATCGTTACGCTAACTATGAGGGCTGTCTGTGGAATGCTACAGGCGTTGTAGTTTGTACTGGTGACGAAACTCAGTGTTACGGTACATGGGTTCCTATTGGGCTTGCTATCCCTGAAAATGAGGGTGGTGGCTCTGAGGGTGGCGGTTCTGAGGGTGGCGGTTCTGAGGGTGGCGGTACTAAACCTCCTGAGTACGGTGATACACCTATTCCGGGCTATACTTATATCAACCCTCTCGACGGCACTTATCCGCCTGGTACTGAGCAAAACCCCGCTAATCCTAATCCTTCTCTTGAGGAGTCTCAGCCTCTTAATACTTTCATGTTTCAGAATAATAGGTTCCGAAATAGGCAGGGGGCATTAACTGTTTATACGGGCACTTTTACTCAAGGCACTGACCCCGTTAAAACTTATTACCAGTACACTCCTGTATCATCAAAAGCCATGTATGACGCTTACTGGAACGGTAAATTCAGAGACTGCGCTTTCCATTCTGGCTTTAATGAGGATCCATTCGTTTGTGAATATCAAGGCCAATCGTCTGACCTGCCTCAACCTCCTGTCAATGCTGGCGGCGGCTCTGGTGGTGGTTCTGGTGGCGGCTCTGAGGGTGGTGGCTCTGAGGGTGGCGGTTCTGAGGGTGGCGGCTCTGAGGGAGGCGGTTCCGGTGGTGGCTCTGGTTCCGGTGATTTTGATTATGAAAAGATGGCAAACGCTAATAAGGGGGCTATGACCGAAAATGCCGATGAAAACGCGCTACAGTCTGACGCTAAAGGCAAACTTGATTCTGTCGCTACTGATTACGGTGCTGCTATCGATGGTTTCATTGGTGACGTTTCCGGCCTTGCTAATGGTAATGGTGCTACTGGTGATTTTGCTGGCTCTAATTCCCAAATGGCTCAAGTCGGTGACGGTGATAATTCACCTTTAATGAATAATTTCCGTCAATATTTACCTTCCCTCCCTCAATCGGTTGAATGTCGCCCTTTTGTCTTTGGCGCTGGGAAACCGTACGAGTTTTCTATTGATTGTGACAAGATCAACCTCTTTCGTGGTGTCTTTGCGTTTCTTTTATATGTTGCCACCTTTATGTATGTATTTTCTACGTTTGCTAACATACTGCGTAATAAGGAGTCTTAATCATGCCAGTTCTTTTGGGTATTCCGTTATTATTGCGTTTCCTCGGTTTCCTTCTGGTAACTTTGTTCGGCTATCTGCTTACTTTTCTTAAAAAGGGCTTCGGTAAGATAGCTATTGCTATTTCATTGTTTCTTGCTCTTATTATTGGGCTTAACTCAATTCTTGTGGGTTATCTCTCTGATATTAGCGCTCAATTACCCTCTGACTTTGTTCAGGGTGTTCAGTTAATTCTCCCGTCTAATGCGCTTCCCTGTTTTTACGTGATATTGTCTGTAAAGGCTGCTATTTTCATTTTTGACGTTAAACAAAAAATCGTTTCTTATTTGGATTGGGATAAATAATATGGCTGTTTATTTTGTAACTGGCAAGCTTGGCTCGGGCAAGACGCTCGTTAGCGTAGGCAAGATCCAGGATAAGATCGTAGCTGGGTGCAAAATAGCAACTAATCTTGATTTAAGGCTTCAAAACCTCCCGCAAGTCGGGAGGTTCGCTAAAACGCCTCGCGTTCTTAGAATACCGGATAAGCCTTCTATATCTGATTTGCTTGCTATTGGGCGCGGTAATGATTCCTACGATGAAAATAAAAACGGCTTGCTTGTTCTCGATGAGTGCGGTACTTGGTTTAATACCCGTTCTTGGAATGATAAGGAAAGACAGCCGATTATTGATTGGTTTCTACATGCTCGTAAATTAGGATGGGATATTATTTTTCTTGTTCAGGACTTATCTATTGTTGATAAACAGGCGCGTTCTGCATTAGCTGAACATGTTGTTTATTGTCGTCGTCTGGACAGAATTACTTTACCTTTTGTCGGTACTTTATATTCTCTTATTACTGGCTCGAAAATGCCTCTGCCTAAATTACATGTTGGCGTTGTTAAATATGGCGATTCTCAATTAAGCCCTACTGTTGAGCGTTGGCTTTATACTGGTAAGAATTTGTATAACGCATATGATACTAAACAGGCTTTTTCTAGTAATTATGATTCCGGTGTTTATTCTTATTTAACGCCTTATTTATCACACGGTCGGTATTTCAAACCATTAAATTTAGGTCAGAAGATGAAATTAACTAAAATATATTTGAAAAAGTTTTCTCGCGTTCTTTGTCTTGCGATTGGATTTGCATCAGCATTTACATATAGTTATATAACCCAACCTAAGCCGGAGGTTAAAAAGGTAGTCTCTCAGACCTATGATTTTGATAAATTCACTATCGATTCTTCTCAGCGTCTTAATCTCAGCTACCGCTACGTTTTCAAGGATTCTAAGGGAAAATTAATTAATAGCGACGATTTACAGAAGCAAGGTTATTCACTCACATATATTGATTTATGTACTGTTTCCATTAAAAAAGGTAATTCAAATGAAATTGTTAAATGTAATTAATTTTGTTTTCTTGATGTTTGTTTCATCATCTTCTTTTGCTCAGGTAATTGAAATGAATAATTCGCCTCTGCGCGATTTTGTAACTTGGTATTCAAAGCAATCAGGCGAATCCGTTATTGTTTCTCCCGATGTAAAAGGTACTGTTACTGTATATTCATCTGACGTTAAACCTGAAAATCTACGCAATTTCTTTATTTCTGTTTTACGTGCAAATAATTTTGATATGGTAGGTTCTAACCCTTCCATTATTCAGAAGTATAATCCAAACAATCAGGATTATATTGATGAATTGCCATCATCTGATAATCAGGAATATGATGATAATTCCGCTCCTTCTGGTGGTTTCTTTGTTCCGCAAAATGATAATGTTACTCAAACTTTTAAAATTAATAACGTTCGGGCCAAGGATTTAATACGAGTAGTCGAGCTCTTTGTAAAGTCTAATACTTCTAAATCCTCAAATGTATTATCTATTGACGGCTCTAATCTATTAGTTGTTAGTGCTCCTAAAGATATTTTAGATAACCTTCCTCAATTCCTTTCAACTGTTGATTTGCCAACTGACCAGATATTGATTGAGGGTTTGATATTTGAGGTTCAGCAAGGTGATGCTTTAGATTTTTCATTTGCTGCTGGCTCTCAGCGTGGCACTGTTGCAGGCGGTGTTAATACTGACCGCCTCACCTCTGTTTTATCTTCTGCTGGTGGTTCGTTCGGTATTTTTAATGGCGATGTTTTAGGGCTATCAGTTCGCGCATTAAAGACTAATAGCCATTCAAAAATATTGTCTGTGCCACGTATTCTTACGCTTTCAGGTCAGAAGGGTTCTATCTCTGTTGGCCAGAATGTCCCTTTTATTACTGGTCGTGTGACTGGTGAATCTGCCAATGTAAATAATCCATTTCAGACGATTGAGCGTCAAAATGTAGGTATTTCCATGAGCGTTTTTCCTGTTGCAATGGCTGGCGGTAATATTGTTCTGGATATTACCAGCAAGGCCGATAGTTTGAGTTCTTCTACTCAGGCAAGTGATGTTATTACTAATCAAAGAAGTATTGCTACAACGGTTAATTTGCGTGATGGACAGACTCTTTTACTCGGTGGCCTCACTGATTATAAAAACACTTCTCAGGATTCTGGCGTACCGTTCCTGTCTAAAATCCCTTTAATCGGCCTCCTGTTTAGCTCCCGCTCTGATTCTAACGAGGAAAGCACGTTATACGTGCTCGTCAAAGCAACCATAGTACGCGCCCTGTAGCGGCGCATTAAGCGCGGCGGGTGTGGTGGTTACGCGCAGCGTGACCGCTACACTTGCCAGCGCCCTAGCGCCCGCTCCTTTCGCTTTCTTCCCTTCCTTTCTCGCCACGTTCGCCGGCTTTCCCCGTCAAGCTCTAAATCGGGGGCTCCCTTTAGGGTTCCGATTTAGTGCTTTACGGCACCTCGACCCCAAAAAACTTGATTTGGGTGATGGTTCACGTAGTGGGCCATCGCCCTGATAGACGGTTTTTCGCCCTTTGACGTTGGAGTCCACGTTCTTTAATAGTGGACTCTTGTTCCAAACTGGAACAACACTCAACCCTATCTCGGGCTATTCTTTTGATTTATAAGGGATTTTGCCGATTTCGGCCTATTGGTTAAAAAATGAGCTGATTTAACAAAAATTTAACGCGAATTTTAATTAGAAAAACTCATCGAGCATCAAATGAAACTGCAATTTATTCATATCAGGATTATCAATACCATATTTTTGAAAAAGCCGTTTCTGTAATGAAGGAGAAAACTCACCGAGGCAGTTCCATAGGATGGCAAGATCCTGGTATCGGTCTGCGATTCCGACTCGTCCAACATCAATACAACCTATTAATTTCCCCTCGTCAAAAATAAGGTTATCAAGTGAGAAATCACCATGAGTGACGACTGAATCCGGTGAGAATGGCAAAAGCTTATGCATTTCTTTCCAGACTTGTTCAACAGGCCAGCCATTACGCTCGTCATCAAAATCACTCGCATCAACCAAACCGTTATTCATTCGTGATTGCGCCTGAGCGAGACGAAATACGCGATCGCTGTTAAAAGGACAATTACAAACAGGAATCGAATGCAACCGGCGCAGGAACACTGCCAGCGCATCAACAATATTTTCACCTGAATCAGGATATTCTTCTAATACCTGGAATGCTGTTTTCCCGGGGATCGCAGTGGTGAGTAACCATGCATCATCAGGAGTACGGATAAAATGCTTGATGGTCGGAAGAGGCATAAATTCCGTCAGCCAGTTTAGTCTGACCATCTCATCTGTAACATCATTGGCAACGCTACCTTTGCCATGTTTCAGAAACAACTCTGGCGCATCGGGCTTCCCATACAATCGATAGATTGTCGCACCTGATTGCCCGACATTATCGCGAGCCCATTTATACCCATATAAATCAGCATCCATGTTGGAATTTAATCGCGGCCTCGAGCAAGACGTTTCCCGTTGAATATGGCTCATAACACCCCTTGTATTACTGTTTATGTAAGCAGACAGTTTTATTGTTCATGATGATATATTTTTATCTTGTGCAATGTAACATCAGAGATTTTGAGACACAACGTGGCTTTCCCAAAATATTAACGTTTACAATTTAAATATTTGCTTATACAATCTTCCTGTTTTTGGGGCTTTTCTGATTATCAACCGGGGTACATATGATTGACATGCTAGTTTTACGATTACCGTTCATCGATTCTCTTGTTTGCTCCAGACTCTCAGGCAATGACCTGATAGCCTTTGTAGACCTCTCAAAAATAGCTACCCTCTCCGGCATTAATTTATCAGCTAGAACGGTTGAATATCATATTGATGGTGATTTGACTGTCTCCGGCCTTTCTCACCCTTTTGAGTCGTTACCGACGCACTACTCAGGCATTGCATTCAAGATCTATGAGGGTTCTAAAAATTTTTATCCTTGCGTTGAAATAAAGGCTTCTCCCGCAAAAGTATTACAGGGTCATAATGTTTTTGGTACAACCGATTTAGCTTTATGCTCTGAGGCTTTATTGCTTAATTTTGCTAATTCTTTGCCTTGCCTGTATGATTTATTGGATGTT\n"
     ]
    }
   ],
   "source": [
    "with open(\"../ref_files_m13/m13_alt/alt_prom_v1_kan.fa\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        print(str(record.seq).upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
